import os
import json
import time
import asyncio
import hashlib
import uuid
from typing import AsyncGenerator, List, Dict, Any
from dotenv import load_dotenv
from openai import OpenAI
from neo4j import GraphDatabase

load_dotenv()


# ==================== ğŸ› ï¸ å·¥å…·ç±»ï¼šå›¾è°±ç®¡ç†å™¨ ====================
class GraphManager:
    """è´Ÿè´£ä¸ Neo4j äº¤äº’çš„æ‰€æœ‰åº•å±‚æ“ä½œ"""

    def __init__(self):
        uri = os.getenv("NEO4J_URI")
        user = os.getenv("NEO4J_USER")
        password = os.getenv("NEO4J_PASSWORD")
        self.driver = GraphDatabase.driver(uri, auth=(user, password))

    def close(self):
        self.driver.close()

    def _generate_id(self, name: str) -> str:
        """ç”Ÿæˆç¡®å®šæ€§ID"""
        return f"node_{hashlib.md5(name.encode('utf-8')).hexdigest()[:8]}"

    def _assign_color(self, group: str) -> str:
        """
        æ ¹æ®å®ä½“ç±»å‹åˆ†é…é¢œè‰² (æ”¯æŒä¸­æ–‡æ˜ å°„å’Œæ¨¡ç³ŠåŒ¹é…)
        å¢å¼ºé€‚é…æ€§ï¼šä¾‹å¦‚ 'äººç‰©'ã€'å¼€å‘è€…'ã€'åˆ›å§‹äºº' éƒ½ä¼šè¢«æ˜ å°„ä¸º Person çš„é¢œè‰²
        """
        # 1. å®šä¹‰åŸºç¡€è‰²ç›˜ (æ–¹ä¾¿ç»Ÿä¸€ä¿®æ”¹)
        colors = {
            "orange": "#ff9900",   # æ¦‚å¿µ/æ ¸å¿ƒ
            "pink": "#ff66cc",     # äººç‰©
            "blue": "#66ccff",     # ä½œå“/ç”µå½±
            "cyan": "#00cc99",     # æŠ€æœ¯
            "purple": "#9966ff",   # åœ°ç‚¹
            "dark_blue": "#4d4dff",# å…¬å¸/ç»„ç»‡
            "grey": "#808080",     # æ—¶é—´/å…¶ä»–
            "default": "#cccccc"   # æœªçŸ¥
        }

        # 2. å®šä¹‰å…³é”®è¯æ˜ å°„è§„åˆ™ (Key = å…³é”®è¯, Value = è‰²ç›˜Key)
        # ä½ å¯ä»¥åœ¨è¿™é‡Œéšæ„æ·»åŠ  DeepSeek å¯èƒ½è¾“å‡ºçš„ä¸­æ–‡è¯æ±‡
        mapping_rules = {
            # === äººç‰©ç±» ===
            "Person": "pink", "äºº": "pink", "äººç‰©": "pink", "ç”¨æˆ·": "pink",
            "æ¼”å‘˜": "pink", "å¯¼æ¼”": "pink", "å¼€å‘è€…": "pink", "åˆ›å§‹äºº": "pink", 
            "CEO": "pink", "ä¸“å®¶": "pink", "ä½œè€…": "pink",
            
            # === å½±è§†/ä½œå“ç±» ===
            "Movie": "blue", "ç”µå½±": "blue", "å½±ç‰‡": "blue", "ä½œå“": "blue", 
            "ä¹¦ç±": "blue", "å°è¯´": "blue", "ç”µè§†å‰§": "blue",
            
            # === æ¦‚å¿µ/æŠ€æœ¯ç±» ===
            "Concept": "orange", "æ¦‚å¿µ": "orange", "æœ¯è¯­": "orange", "å®šä¹‰": "orange",
            "Technology": "cyan", "æŠ€æœ¯": "cyan", "ç§‘æŠ€": "cyan", "å·¥å…·": "cyan", "è¯­è¨€": "cyan",
            
            # === åœ°ç‚¹ç±» ===
            "Location": "purple", "åœ°ç‚¹": "purple", "åŸå¸‚": "purple", "å›½å®¶": "purple", "åœ°å€": "purple",
            
            # === å…¬å¸/ç»„ç»‡ç±» ===
            "Company": "dark_blue", "å…¬å¸": "dark_blue", "ä¼ä¸š": "dark_blue", 
            "æœºæ„": "dark_blue", "å“ç‰Œ": "dark_blue", "é›†å›¢": "dark_blue",
            
            # === æ—¶é—´ç±» ===
            "Date": "grey", "æ—¶é—´": "grey", "æ—¥æœŸ": "grey", "å¹´ä»½": "grey", "å¹´ä»£": "grey"
        }
        
        # 3. åŒ¹é…é€»è¾‘
        if not group:
            return colors["default"]
            
        # 3.1 å°è¯•ç›´æ¥ç²¾ç¡®åŒ¹é… (æœ€å¿«)
        # ä¾‹å¦‚: group="å¼€å‘è€…" -> å‘½ä¸­ -> è¿”å› pink
        if group in mapping_rules:
            return colors[mapping_rules[group]]
            
        # 3.2 å°è¯•æ¨¡ç³ŠåŒ¹é… (åŒ…å«å…³ç³»)
        # ä¾‹å¦‚: group="ç§‘å¹»ç”µå½±" -> åŒ…å« "ç”µå½±" -> è¿”å› blue
        # ä¾‹å¦‚: group="è‘—åäººç‰©" -> åŒ…å« "äººç‰©" -> è¿”å› pink
        for key, color_key in mapping_rules.items():
            if key in group:
                return colors[color_key]
                
        # 4. å¦‚æœéƒ½åŒ¹é…ä¸ä¸Šï¼Œè¿”å›é»˜è®¤ç°è‰²
        return colors["default"]

    def search_subgraph(self, keywords: List[str]) -> str:
        """
        ã€RAG æ ¸å¿ƒä¼˜åŒ–ç‰ˆã€‘ï¼šç²¾ç¡®æŸ¥è¯¢å®ä½“é—´çš„å…·ä½“å…³ç³»
        """
        if not keywords:
            return ""

        context_texts = []
        with self.driver.session() as session:
            # === ä¿®æ”¹ç‚¹ 1: æŸ¥è¯¢å…·ä½“çš„ name å±æ€§ ===
            # æˆ‘ä»¬ä¹‹å‰æŸ¥è¯¢çš„æ˜¯ type(r)ï¼Œé‚£åªæ˜¯ "RELATED"ã€‚
            # ç°åœ¨æˆ‘ä»¬æŸ¥è¯¢ r.nameï¼Œè¿™é‡Œå­˜å‚¨äº† "å¯¼æ¼”"ã€"ä½œè€…" ç­‰å…·ä½“å«ä¹‰ã€‚
            query = """
            UNWIND $keywords AS kw
            MATCH (n:Entity) WHERE n.name CONTAINS kw
            OPTIONAL MATCH (n)-[r]-(m)
            RETURN n.name, r.name, m.name
            LIMIT 30
            """
            result = session.run(query, keywords=keywords)

            seen = set()
            for record in result:
                n_name = record["n.name"]
                rel_name = record["r.name"]  # å–å‡ºå…·ä½“çš„â€œä½œè€…â€ã€â€œå¯¼æ¼”â€
                m_name = record["m.name"]

                if rel_name and m_name:
                    # æ‹¼æ¥æˆè‡ªç„¶è¯­è¨€ï¼Œä¾‹å¦‚ï¼šæµæµªåœ°çƒ --[å¯¼æ¼”]--> éƒ­å¸†
                    fact = f"{n_name} çš„å…³ç³»æ˜¯ [{rel_name}] å¯¹è±¡æ˜¯ {m_name}"
                else:
                    fact = f"å®ä½“: {n_name}"

                if fact not in seen:
                    context_texts.append(fact)
                    seen.add(fact)

        return "\n".join(context_texts)

    def update_graph(self, session_id: str, extraction_data: Dict[str, Any]) -> Dict[str, Any]:
        """å°†æå–çš„ JSON æ•°æ®å†™å…¥ Neo4j"""
        raw_nodes = extraction_data.get("entities", [])
        raw_relations = extraction_data.get("relations", [])

        frontend_update_data = {"nodes": [], "links": []}

        if not raw_nodes and not raw_relations:
            return frontend_update_data

        with self.driver.session() as session:
            # 1. èŠ‚ç‚¹å†™å…¥ (ä¿æŒä¸å˜)
            for item in raw_nodes:
                if not isinstance(item, dict) or 'name' not in item: continue

                node_id = self._generate_id(item['name'])
                group = item.get('type', 'Concept')

                frontend_node = {
                    "id": node_id, "name": item['name'], "group": group,
                    "color": self._assign_color(group), "val": 15
                }
                frontend_update_data["nodes"].append(frontend_node)

                session.run("""
                    MERGE (n:Entity {id: $id})
                    SET n.name = $name, n.group = $group, n.color = $color
                """, **frontend_node)

            # 2. å…³ç³»å†™å…¥ (ä¿æŒä¸å˜ï¼Œä½†å¼ºè°ƒ r.name çš„é‡è¦æ€§)
            for item in raw_relations:
                if not isinstance(item, dict) or 'head' not in item or 'tail' not in item: continue

                source_id = self._generate_id(item['head'])
                target_id = self._generate_id(item['tail'])
                rel_name = item.get('relation', 'å…³è”')  # å…·ä½“çš„â€œä½œè€…â€ã€â€œä½äºâ€

                frontend_link = {
                    "source": source_id, "target": target_id,
                    "relationship": rel_name, "width": 2
                }
                frontend_update_data["links"].append(frontend_link)

                # === å…³é”®é€»è¾‘ ===
                # æˆ‘ä»¬ä¾ç„¶ä½¿ç”¨é€šç”¨çš„ :RELATED ç±»å‹ï¼Œå› ä¸º Neo4j æ— æ³•å‚æ•°åŒ–å…³ç³»ç±»å‹ã€‚
                # ä½†æ˜¯æˆ‘ä»¬å°†å…·ä½“çš„ rel_name å­˜å…¥ {name: $rel} å±æ€§ä¸­ã€‚
                session.run("""
                    MATCH (s:Entity {id: $sid}), (t:Entity {id: $tid})
                    MERGE (s)-[r:RELATED {name: $rel}]->(t)
                """, sid=source_id, tid=target_id, rel=rel_name)

        return frontend_update_data


# ==================== ğŸ§  æ ¸å¿ƒç±»ï¼šåŒè„‘å¤„ç†å™¨ ====================
class DualBrain:
    def __init__(self):
        self.client = OpenAI(
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url=os.getenv("DEEPSEEK_BASE_URL")
        )
        self.graph_manager = GraphManager()

    async def _extract_search_keywords(self, user_prompt: str) -> List[str]:
        """ã€åå°è„‘ã€‘ï¼šæå–å…³é”®è¯"""
        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "æå–ç”¨æˆ·è¾“å…¥ä¸­çš„æ ¸å¿ƒå®ä½“åç§°ã€‚åªè¾“å‡ºå…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ã€‚"},
                    {"role": "user", "content": user_prompt}
                ],
                stream=False
            )
            content = response.choices[0].message.content
            return [k.strip() for k in content.replace("ï¼Œ", ",").split(",") if k.strip()]
        except Exception:
            return []

    async def _fast_brain_generate(self, user_prompt: str, context: str) -> AsyncGenerator[str, None]:
        """ã€å‰å°è„‘ã€‘ï¼šåŸºäºå…·ä½“å…³ç³»ä¸Šä¸‹æ–‡å›ç­”"""

        # === ä¿®æ”¹ç‚¹ 2: å¢å¼º System Prompt ===
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½åŠ©æ‰‹ã€‚"
        if context:
            system_prompt += f"\n\nã€çŸ¥è¯†å›¾è°±æ£€ç´¢ç»“æœã€‘:\n{context}\n\nè¯·æ³¨æ„ï¼šä¸Šæ–‡ä¸­çš„'å…³ç³»æ˜¯ [XXX]'è¡¨ç¤ºå®ä½“é—´çš„å…·ä½“è”ç³»ã€‚è¯·ä¾æ®è¿™äº›å…·ä½“å…³ç³»å›ç­”ç”¨æˆ·ã€‚"
        else:
            system_prompt += "\n\nå½“å‰çŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·åˆ©ç”¨ä½ çš„é€šç”¨çŸ¥è¯†å›ç­”ã€‚"

        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            stream=True,
            temperature=0.7
        )

        for chunk in response:
            if chunk.choices[0].delta.content:
                yield f"data: {json.dumps({'type': 'chunk', 'id': f'resp_{uuid.uuid4().hex[:6]}', 'content': chunk.choices[0].delta.content})}\n\n"
                await asyncio.sleep(0.01)

    async def _slow_brain_learn(self, session_id: str, user_prompt: str) -> AsyncGenerator[str, None]:
        """ã€åå°è„‘ã€‘ï¼šæå–å…·ä½“å…³ç³»"""
        yield f"data: {json.dumps({'type': 'control', 'status': 'thinking', 'payload': 'æ­£åœ¨åˆ†æå…·ä½“å…³ç³»...'})}\n\n"

        # === ä¿®æ”¹ç‚¹ 3: ä¼˜åŒ–æå– Prompt ===
        # å¼ºåˆ¶è¦æ±‚æå–å…·ä½“çš„åŠ¨è¯æˆ–åè¯å…³ç³»ï¼Œè€Œä¸æ˜¯ç¬¼ç»Ÿçš„â€œç›¸å…³â€
        extraction_prompt = f"""
        è¯·åˆ†æç”¨æˆ·çš„è¾“å…¥ï¼Œæå–äº‹å®æ€§ä¸‰å…ƒç»„ã€‚
        ç”¨æˆ·è¾“å…¥ï¼š"{user_prompt}"

        è¦æ±‚ï¼š
        1. å¦‚æœæ˜¯æé—®ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚
        2. å¦‚æœæ˜¯é™ˆè¿°äº‹å®ï¼Œæå–å®ä½“å’Œ**å…·ä½“å…³ç³»**ã€‚
        3. **å…³ç³»(relation)** å¿…é¡»æ˜¯å…·ä½“çš„åŠ¨è¯æˆ–åè¯ï¼Œä¾‹å¦‚ï¼š"å¯¼æ¼”"ã€"ä½œè€…"ã€"ä½äº"ã€"å±äº"ã€"CEO"ã€‚ä¸è¦ä½¿ç”¨ "ç›¸å…³"ã€"è”ç³»" è¿™ç§æ¨¡ç³Šè¯ã€‚
        4. è¿”å›çº¯ JSON:
        {{
            "entities": [{{"name": "å®ä½“å", "type": "ç±»å‹"}}],
            "relations": [{{"head": "å¤´å®ä½“", "tail": "å°¾å®ä½“", "relation": "å…·ä½“å…³ç³»è¯"}}]
        }}
        """

        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": extraction_prompt}],
                response_format={"type": "json_object"}
            )

            content = response.choices[0].message.content
            extracted_json = json.loads(content)

            # å®¹é”™
            if "entities" not in extracted_json: extracted_json["entities"] = []
            if "relations" not in extracted_json: extracted_json["relations"] = []

            # å†™å…¥æ•°æ®åº“
            loop = asyncio.get_running_loop()
            frontend_data = await loop.run_in_executor(
                None,
                self.graph_manager.update_graph,
                session_id,
                extracted_json
            )

            if frontend_data["nodes"] or frontend_data["links"]:
                graph_event = {
                    "type": "graph_update", "action": "merge",
                    "data": frontend_data, "timestamp": int(time.time() * 1000)
                }
                yield f"data: {json.dumps(graph_event)}\n\n"
                yield f"data: {json.dumps({'type': 'control', 'status': 'finish', 'stop_reason': 'learned', 'summary': {'newNodes': len(frontend_data['nodes'])}})}\n\n"
            else:
                yield f"data: {json.dumps({'type': 'control', 'status': 'finish', 'payload': 'æœªå‘ç°æ–°çŸ¥è¯†'})}\n\n"

        except Exception as e:
            print(f"å­¦ä¹ è¿‡ç¨‹å‡ºé”™: {e}")
            yield f"data: {json.dumps({'type': 'control', 'status': 'error', 'payload': str(e)})}\n\n"

    async def think(self, session_id: str, user_prompt: str) -> AsyncGenerator[str, None]:
        
        yield f"data: {json.dumps({'type': 'control', 'status': 'start'})}\n\n"

        yield f"data: {json.dumps({'type': 'control', 'status': 'thinking', 'payload': 'æ­£åœ¨æ£€ç´¢å…·ä½“å…³ç³»...'})}\n\n"
        keywords = await self._extract_search_keywords(user_prompt)
        loop = asyncio.get_running_loop()
        graph_context = await loop.run_in_executor(None, self.graph_manager.search_subgraph, keywords)

        if graph_context:
            yield f"data: {json.dumps({'type': 'control', 'status': 'thinking', 'payload': 'å·²åŠ è½½å…³è”çŸ¥è¯†'})}\n\n"

        async for event in self._fast_brain_generate(user_prompt, graph_context):
            yield event

        async for event in self._slow_brain_learn(session_id, user_prompt):
            yield event

        yield f"data: {json.dumps({'type': 'control', 'status': 'closed'})}\n\n"

    def close(self):
        self.graph_manager.close()